Controllability  操纵

Controllability in responsible AI refers to the ability to monitor and guide an AI system's behavior to align with human values and intent. It involves developing architectures that are controllable, so that any unintended issues can be managed and addressed.  
负责任的 AI 中的可控性是指监控和指导 AI 系统的行为以符合人类价值观和意图的能力。它涉及开发可控的架构，以便管理和解决任何意外问题。
By ensuring controllability, responsible AI can help mitigate risks, promote fairness and transparency, and ensure that AI systems benefit society as a whole. 
通过确保可控性，负责任的 AI 可以帮助降低风险，促进公平和透明，并确保 AI 系统造福整个社会。

Increased trust and reputation
提高信任和声誉

Customers are more likely to interact with AI applications, if they believe the system is fair and safe. This enhances their reputation and brand value. 
如果客户认为 AI 应用程序是公平和安全的，他们就更有可能与 AI 应用程序进行交互。这提高了他们的声誉和品牌价值。

Regulatory compliance  法规遵从性

As AI regulations emerge, companies with robust ethical AI frameworks are better positioned to comply with guidelines on data privacy, fairness, accountability, and transparency.
随着 AI 法规的出台，拥有强大的道德 AI 框架的公司可以更好地遵守有关数据隐私、公平性、问责制和透明度的准则。

AI governance provides the guiding processes and institutional mechanisms to help ensure responsibility, risk mitigation, and oversight for AI from research and development (R&D) to deployment. It encourages maximizing societal benefits while minimizing harm from AI. Governance is crucial for responsible adoption.
AI 治理提供了指导流程和制度机制，以帮助确保 AI 从研发 （R&D） 到部署的责任、风险缓解和监督。它鼓励最大限度地提高社会利益，同时最大限度地减少 AI 的危害。治理对于负责任的采用至关重要。


Explainability empowers users to verify system functionality, check for unwanted biases, increase useful human control, and place appropriate trust in AI systems. This dimension of AI promotes the responsible development and deployment of AI technology for the benefit of society. Without explainability, AI could lose public trust because of inscrutable failures.

可解释性使用户能够验证系统功能、检查不需要的偏差、增加有用的人工控制，并适当信任 AI 系统。AI 的这一维度促进了 AI 技术的负责任开发和部署，以造福社会。如果没有可解释性，AI 可能会因难以捉摸的失败而失去公众信任。
